{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMhqu0eeTzJVLH4vYNnucTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orattanathon/RL/blob/main/rescueWombat_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JoMUuntXqcH"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "from contextlib import closing\n",
        "from io import StringIO\n",
        "from gym import utils\n",
        "import time\n",
        "from gym.envs.toy_text import discrete\n",
        "from gym.envs.registration import register\n",
        "\n",
        "\n",
        "MAP = [\n",
        "        \"SPPFP\",\n",
        "        \"PBPFP\",\n",
        "        \"PPWBF\",\n",
        "        \"PBPPP\",\n",
        "        \"PFPPG\"\n",
        "       ]\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaivKxiG2PQS",
        "outputId": "9c175b45-e214-4348-942a-98310dda4efb"
      },
      "source": [
        "env_dict = gym.envs.registration.registry.env_specs.copy()\n",
        "for env in env_dict:\n",
        "    if 'rescueWombat-v0' in env:\n",
        "        print(\"Remove {} from registry\".format(env))\n",
        "        del gym.envs.registration.registry.env_specs[env]\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Remove rescueWombat-v0 from registry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfIdQz65yFPF"
      },
      "source": [
        "class rescueWombat(discrete.DiscreteEnv):\n",
        " \n",
        "     metadata = {'render.modes': ['console']}\n",
        "     def __init__(self):\n",
        "\n",
        "        self.desc = np.asarray(MAP, dtype='c')\n",
        "        num_states = 50\n",
        "        num_actions = 5\n",
        "        nrow = 5\n",
        "        ncol = 5\n",
        "        max_row = nrow - 1\n",
        "        max_col = ncol - 1\n",
        "        picked = False\n",
        "\n",
        "        isd = np.array(self.desc == b'S').astype('float64').ravel()\n",
        "\n",
        "        P = {state: {action: []\n",
        "                     for action in range(num_actions)} for state in range(num_states)}\n",
        "\n",
        "        def s_encode(row,col,picked):\n",
        "          if not picked:\n",
        "             i = row\n",
        "             i *= ncol\n",
        "             i += col\n",
        "          else:\n",
        "             i = row\n",
        "             i *= ncol\n",
        "             i += col\n",
        "             i = i*2\n",
        "          return i\n",
        "\n",
        "        for row in range(nrow):\n",
        "            for col in range(ncol):\n",
        "                    state = s_encode(row,col,picked)\n",
        "\n",
        "                    if self.desc[row,col] == b'S':\n",
        "                        isd[state] += 1\n",
        "\n",
        "                        for action in range(num_actions):\n",
        "                            new_row, new_col = row, col \n",
        "                            reward = -1 #default reward for every action taken\n",
        "                            done = False\n",
        "                            if not picked:\n",
        "                               if action == 0: #DOWN\n",
        "                                  if self.desc[row + 1, max_row] in b'GP':\n",
        "                                     new_row = min(row + 1, max_row)\n",
        "                                  elif self.desc[row + 1, max_row] in b'B':\n",
        "                                     new_row = row #can't move\n",
        "                               if action == 1: #UP\n",
        "                                  if self.desc[row - 1, 0] in b'GP':\n",
        "                                     new_row = max(row - 1, 0)\n",
        "                                  elif self.desc[row - 1, 0] in b'B':\n",
        "                                     new_row = row  #can't move\n",
        "                               if action == 2: #RIGHT\n",
        "                                  if self.desc[col + 1, max_col] in b'GP':\n",
        "                                    new_col = min(col + 1, max_col)\n",
        "                                  elif self.desc[col + 1, max_col] in b'B':\n",
        "                                     new_col = col #can't move\n",
        "                               if action == 3: #LEFT\n",
        "                                  if self.desc[col + 1, max_col] in b'GP':\n",
        "                                    new_col = min(col + 1, max_col)\n",
        "                                  elif self.desc[col + 1, max_col]in b'B':\n",
        "                                     new_col = col\n",
        "                               if action == 4: #PICKUP\n",
        "                                  if self.desc[row, col] != b'W': \n",
        "                                     print ('Wombat is not here')\n",
        "                                  elif self.desc[max_row, col] == b'W':\n",
        "                                     reward = 20  \n",
        "                                     self.picked == True\n",
        "                           \n",
        "                            if picked: \n",
        "                                if action == 0:  #DOWN\n",
        "                                  if self.desc[row + 1, max_row] in b'GP':\n",
        "                                     new_row = min(row + 1, max_row)\n",
        "                                  elif self.desc[row + 1, max_row] in b'B':\n",
        "                                     new_row = row\n",
        "                                if action == 1: #UP\n",
        "                                   if self.desc[row - 1, 0] in b'GP':\n",
        "                                     new_row = max(row - 1, 0)\n",
        "                                   elif self.desc[row - 1, 0] in b'B':\n",
        "                                     new_row = row\n",
        "                                if action == 2: #RIGHT\n",
        "                                  if self.desc[col + 1, max_col] in b'GP':\n",
        "                                    new_col = min(col + 1, max_col)\n",
        "                                  elif self.desc[col + 1, max_col] in b'B':\n",
        "                                     new_col = col\n",
        "                                if action == 3:  #LEFT\n",
        "                                  if self.desc[col + 1, max_col] in b'GP':\n",
        "                                    new_col = min(col + 1, max_col)\n",
        "                                  elif self.desc[col + 1, max_col]in b'B':\n",
        "                                     new_col = col\n",
        "                                if action == 4:  #PICKUP\n",
        "                                    print ('Wombat has been picked up, find the goal')\n",
        "                          \n",
        "                            if self.desc[new_row,new_col] == b'F': #walk into the fire\n",
        "                               reward = -30\n",
        "                               done = True  #exit episode...failed\n",
        "                            if self.desc[new_row,new_col] == b'G' and not picked:\n",
        "                               reward = -30  #reach goal before picking up the wombat\n",
        "                            elif self.desc[new_row,new_col] == b'G' and picked:\n",
        "                               reward = 30  #Success\n",
        "                               done = True\n",
        "                            new_state = s_encode(new_row, new_col,picked)\n",
        "                            P[state][action].append((1.0, new_state, reward, done))\n",
        "                  \n",
        "        isd /= isd.sum()\n",
        "        discrete.DiscreteEnv.__init__(self, num_states, num_actions, P, isd)\n",
        "\n",
        "    \n",
        "\n",
        "register(\n",
        "    id='rescueWombat-v0',\n",
        "    entry_point=f\"{__name__}:rescueWombat\"\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkRu3siOyfLR",
        "outputId": "fe3f403c-a296-4e9b-9c45-582d5595115a"
      },
      "source": [
        "env = gym.make('rescueWombat-v0')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wombat is not here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlVlygMC868G",
        "outputId": "db091b87-42fc-4503-a73a-61f8198c4a0e"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "action_size = env.action_space.n\n",
        "print(\"Action size \", action_size)\n",
        "\n",
        "state_size = env.observation_space.n\n",
        "print(\"State size \", state_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action size  5\n",
            "State size  50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-clhWhG9EQB",
        "outputId": "d8625b5b-37e9-4286-f2e4-1a5c7d6fa0c1"
      },
      "source": [
        "print(env.action_space)\n",
        "print(env.observation_space)\n",
        "\n",
        "print(env.desc)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discrete(5)\n",
            "Discrete(50)\n",
            "[[b'S' b'P' b'P' b'F' b'P']\n",
            " [b'P' b'B' b'P' b'F' b'P']\n",
            " [b'P' b'P' b'W' b'B' b'F']\n",
            " [b'P' b'B' b'P' b'P' b'P']\n",
            " [b'P' b'F' b'P' b'P' b'G']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4p3D_Y4PO1c"
      },
      "source": [
        "class sarsa_policy:\n",
        "    def __init__(self, epsilon, alpha, gamma, num_state, num_actions, action_space):\n",
        "        self.num_actions = num_actions\n",
        "        self.num_states = num_states\n",
        "        self.epsilon = epsilon #exploration degree\n",
        "        self.alpha = alpha  #learn rate\n",
        "        self.gamma = gamma  #discount\n",
        "        self.Q = np.zeros((self.num_states, self.num_actions)) #Q_Table\n",
        "        self.action_space = action_space\n",
        "\n",
        "        self.last_action = None\n",
        "        self.last_state = None\n",
        "        \n",
        "        def choose_action(self, state): #policy\n",
        "            \n",
        "           exp_tradeoff = random.uniform(0, 1) #select a random number\n",
        " \n",
        "           if exp_tradeoff < self.epsilon:   #exploration\n",
        "              action = self.action_space.sample()\n",
        "           else:\n",
        "              action = np.argmax(self.Q[state, :]) #greedy action\n",
        "           return action\n",
        "\n",
        "        def update(self, prev_state, next_state, reward, prev_action, next_action): #update Qtable\n",
        "\n",
        "           predict = self.Q[prev_state, prev_action]\n",
        "           target = reward + self.gamma * self.Q[next_state, next_action]\n",
        "           self.Q[prev_state, prev_action] += self.alpha * (target - predict)\n",
        "\n",
        "           total_episodes = 100\n",
        "           i = 1\n",
        "        for i in range(total_episodes):\n",
        "           prev_state = env.reset()\n",
        "           prev_action = choose_action(prev_state)\n",
        "           rewards = []\n",
        "           while True:\n",
        "        \n",
        "               next_state, reward, done, info = env.step(prev_action)\n",
        "               next_action = agent.choose_action(new_state) \n",
        "               agent.update(prev_state, new_state, reward, prev_action, next_action) \n",
        "      \n",
        "               prev_state = new_state \n",
        "               prev_action = next_action\n",
        "               rewards.append(reward)\n",
        "               i += i\n",
        "               if done: \n",
        "                  cumulativeReward = sum(reward)\n",
        "                  break"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}